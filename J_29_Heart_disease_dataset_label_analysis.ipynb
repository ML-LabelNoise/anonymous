{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Heart Disease Label Noise Analysis (with Random Forest Included)\n",
        "\"\"\"\n",
        "\n",
        "!pip install ucimlrepo\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "###############################################################################\n",
        "# 1) Load and Preprocess the Heart Disease Data\n",
        "###############################################################################\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "print(\"Fetching Heart Disease dataset from UCIML...\")\n",
        "heart_disease = fetch_ucirepo(id=45)\n",
        "X = heart_disease.data.features\n",
        "y = heart_disease.data.targets\n",
        "\n",
        "# Combine features and target into a single DataFrame\n",
        "data = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Convert all columns to numeric\n",
        "for col in data.columns:\n",
        "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "\n",
        "# Drop rows with missing values\n",
        "data = data.dropna()\n",
        "\n",
        "print(\"First 5 rows of the dataset after numeric conversion and dropping NAs:\")\n",
        "print(data.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(data.info())\n",
        "\n",
        
        "data['num'] = data['num'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "target = 'num'\n",
        "features = data.columns.drop(target)\n",
        "\n",
        "categorical_vars = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal', 'ca']\n",
        "data_encoded = pd.get_dummies(data, columns=[c for c in categorical_vars if c in data.columns], drop_first=True)\n",
        "\n",
        "X = data_encoded.drop(columns=[target], errors='ignore')\n",
        "y = data_encoded[target].astype(int)\n",
        "\n",
        "print(\"\\nClass Distribution in Dataset (0 = no disease, 1 = disease):\")\n",
        "print(y.value_counts())\n",
        "\n",
        "###############################################################################\n",
        "# 2) Split, Scale, and Define Models\n",
        "###############################################################################\n",
        "\n",
        "# Split data (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_colors = {\n",
        "    'Logistic Regression': 'blue',\n",
        "    'Decision Tree': 'green',\n",
        "    'Naive Bayes': 'purple',\n",
        "    'K-Nearest Neighbors': 'brown',\n",
        "    'Support Vector Machine': 'red',\n",
        "    'Random Forest': 'orange'\n",
        "}\n",
        "\n",
        "models = {\n",
        "    'Support Vector Machine': SVC(probability=True, random_state=RANDOM_STATE),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "###############################################################################\n",
        "# 3) Simulate Label Noise, Train, and Collect Metrics\n",
        "###############################################################################\n",
        "\n",
        "noise_levels = np.arange(0.00, 0.45, 0.05)\n",
        "\n",
        "# Data structures to store metrics\n",
        "ACC_values = {m: {nl: [] for nl in noise_levels} for m in models}\n",
        "TPR_values = {m: {nl: [] for nl in noise_levels} for m in models}\n",
        "TNR_values = {m: {nl: [] for nl in noise_levels} for m in models}\n",
        "\n",
        "print(\"\\nStarting model training and evaluation with simulated label noise...\\n\")\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    for noise_level in noise_levels:\n",
        "        conf_matrix_sum = np.zeros((2, 2), dtype=int)\n",
        "\n",
        "        for iteration in range(10):\n",
        "            iter_seed = RANDOM_STATE + iteration\n",
        "\n",
        "            X_train_, X_test_, y_train_, y_test_ = train_test_split(\n",
        "                X, y, test_size=0.5, stratify=y, random_state=iter_seed\n",
        "            )\n",
        "\n",
        "            scaler_iter = StandardScaler()\n",
        "            X_train_scaled_ = scaler_iter.fit_transform(X_train_)\n",
        "            X_test_scaled_ = scaler_iter.transform(X_test_)\n",
        "\n",
        "            # Introduce label noise in *training* set\n",
        "            y_train_noisy = y_train_.copy()\n",
        "            num_noisy = int(noise_level * len(y_train_noisy))\n",
        "            np.random.seed(iter_seed)\n",
        "            noisy_indices = np.random.choice(len(y_train_noisy), size=num_noisy, replace=False)\n",
        "            y_train_noisy.iloc[noisy_indices] = 1 - y_train_noisy.iloc[noisy_indices]\n",
        "\n",
        "            smote = SMOTE(random_state=iter_seed)\n",
        "            X_train_res, y_train_res = smote.fit_resample(X_train_scaled_, y_train_noisy)\n",
        "\n",
        "            model.fit(X_train_res, y_train_res)\n",
        "            y_pred = model.predict(X_test_scaled_)\n",
        "\n",
        "            cm = confusion_matrix(y_test_, y_pred, labels=[0, 1])\n",
        "            conf_matrix_sum += cm\n",
        "\n",
        "            TN, FP, FN, TP = cm.ravel()\n",
        "            acc = accuracy_score(y_test_, y_pred)\n",
        "            tpr = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "            tnr = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
        "\n",
        "            ACC_values[model_name][noise_level].append(acc)\n",
        "            TPR_values[model_name][noise_level].append(tpr)\n",
        "            TNR_values[model_name][noise_level].append(tnr)\n",
        "\n",
        "        # Print the aggregated confusion matrix for this noise level\n",
        "        print(f\"  Noise Level: {int(noise_level * 100)}%\")\n",
        "        print(\"  Confusion Matrix (sum over runs):\\n\", conf_matrix_sum)\n",
        "\n",
        "    print(f\"  -> Completed label noise evaluations for {model_name}\\n\")\n",
        "\n",
        "print(\"All models evaluated under different noise levels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcf_SsAJ9ND3",
        "outputId": "b686959e-a69d-497c-ad68-3abcb863e208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Fetching Heart Disease dataset from UCIML...\n",
            "First 5 rows of the dataset after numeric conversion and dropping NAs:\n",
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
            "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
            "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
            "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
            "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
            "\n",
            "    ca  thal  num  \n",
            "0  0.0   6.0    0  \n",
            "1  3.0   3.0    2  \n",
            "2  2.0   7.0    1  \n",
            "3  0.0   3.0    0  \n",
            "4  0.0   3.0    0  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 297 entries, 0 to 301\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       297 non-null    int64  \n",
            " 1   sex       297 non-null    int64  \n",
            " 2   cp        297 non-null    int64  \n",
            " 3   trestbps  297 non-null    int64  \n",
            " 4   chol      297 non-null    int64  \n",
            " 5   fbs       297 non-null    int64  \n",
            " 6   restecg   297 non-null    int64  \n",
            " 7   thalach   297 non-null    int64  \n",
            " 8   exang     297 non-null    int64  \n",
            " 9   oldpeak   297 non-null    float64\n",
            " 10  slope     297 non-null    int64  \n",
            " 11  ca        297 non-null    float64\n",
            " 12  thal      297 non-null    float64\n",
            " 13  num       297 non-null    int64  \n",
            "dtypes: float64(3), int64(11)\n",
            "memory usage: 34.8 KB\n",
            "None\n",
            "\n",
            "Class Distribution in Dataset (0 = no disease, 1 = disease):\n",
            "num\n",
            "0    160\n",
            "1    137\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Starting model training and evaluation with simulated label noise...\n",
            "\n",
            "Evaluating Support Vector Machine...\n",
            "  Noise Level: 0%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[677 123]\n",
            " [154 536]]\n",
            "  Noise Level: 5%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[668 132]\n",
            " [166 524]]\n",
            "  Noise Level: 10%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[665 135]\n",
            " [163 527]]\n",
            "  Noise Level: 15%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[657 143]\n",
            " [176 514]]\n",
            "  Noise Level: 20%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[646 154]\n",
            " [166 524]]\n",
            "  Noise Level: 25%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[636 164]\n",
            " [187 503]]\n",
            "  Noise Level: 30%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[624 176]\n",
            " [203 487]]\n",
            "  Noise Level: 35%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[579 221]\n",
            " [204 486]]\n",
            "  Noise Level: 40%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[510 290]\n",
            " [241 449]]\n",
            "  -> Completed label noise evaluations for Support Vector Machine\n",
            "\n",
            "Evaluating Logistic Regression...\n",
            "  Noise Level: 0%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[671 129]\n",
            " [148 542]]\n",
            "  Noise Level: 5%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[656 144]\n",
            " [165 525]]\n",
            "  Noise Level: 10%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[654 146]\n",
            " [167 523]]\n",
            "  Noise Level: 15%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[630 170]\n",
            " [176 514]]\n",
            "  Noise Level: 20%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[627 173]\n",
            " [175 515]]\n",
            "  Noise Level: 25%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[593 207]\n",
            " [191 499]]\n",
            "  Noise Level: 30%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[560 240]\n",
            " [211 479]]\n",
            "  Noise Level: 35%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[534 266]\n",
            " [215 475]]\n",
            "  Noise Level: 40%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[473 327]\n",
            " [244 446]]\n",
            "  -> Completed label noise evaluations for Logistic Regression\n",
            "\n",
            "Evaluating K-Nearest Neighbors...\n",
            "  Noise Level: 0%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[669 131]\n",
            " [170 520]]\n",
            "  Noise Level: 5%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[648 152]\n",
            " [176 514]]\n",
            "  Noise Level: 10%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[659 141]\n",
            " [172 518]]\n",
            "  Noise Level: 15%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[629 171]\n",
            " [186 504]]\n",
            "  Noise Level: 20%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[624 176]\n",
            " [196 494]]\n",
            "  Noise Level: 25%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[582 218]\n",
            " [229 461]]\n",
            "  Noise Level: 30%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[544 256]\n",
            " [230 460]]\n",
            "  Noise Level: 35%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[527 273]\n",
            " [238 452]]\n",
            "  Noise Level: 40%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[488 312]\n",
            " [263 427]]\n",
            "  -> Completed label noise evaluations for K-Nearest Neighbors\n",
            "\n",
            "Evaluating Decision Tree...\n",
            "  Noise Level: 0%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[588 212]\n",
            " [207 483]]\n",
            "  Noise Level: 5%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[569 231]\n",
            " [238 452]]\n",
            "  Noise Level: 10%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[545 255]\n",
            " [228 462]]\n",
            "  Noise Level: 15%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[514 286]\n",
            " [244 446]]\n",
            "  Noise Level: 20%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[533 267]\n",
            " [266 424]]\n",
            "  Noise Level: 25%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[478 322]\n",
            " [276 414]]\n",
            "  Noise Level: 30%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[485 315]\n",
            " [306 384]]\n",
            "  Noise Level: 35%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[435 365]\n",
            " [309 381]]\n",
            "  Noise Level: 40%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[433 367]\n",
            " [303 387]]\n",
            "  -> Completed label noise evaluations for Decision Tree\n",
            "\n",
            "Evaluating Naive Bayes...\n",
            "  Noise Level: 0%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[628 172]\n",
            " [269 421]]\n",
            "  Noise Level: 5%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[637 163]\n",
            " [319 371]]\n",
            "  Noise Level: 10%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[484 316]\n",
            " [271 419]]\n",
            "  Noise Level: 15%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[464 336]\n",
            " [283 407]]\n",
            "  Noise Level: 20%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[454 346]\n",
            " [253 437]]\n",
            "  Noise Level: 25%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[439 361]\n",
            " [254 436]]\n",
            "  Noise Level: 30%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[431 369]\n",
            " [256 434]]\n",
            "  Noise Level: 35%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[409 391]\n",
            " [217 473]]\n",
            "  Noise Level: 40%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[381 419]\n",
            " [237 453]]\n",
            "  -> Completed label noise evaluations for Naive Bayes\n",
            "\n",
            "Evaluating Random Forest...\n",
            "  Noise Level: 0%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[686 114]\n",
            " [187 503]]\n",
            "  Noise Level: 5%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[664 136]\n",
            " [184 506]]\n",
            "  Noise Level: 10%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[651 149]\n",
            " [170 520]]\n",
            "  Noise Level: 15%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[645 155]\n",
            " [185 505]]\n",
            "  Noise Level: 20%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[621 179]\n",
            " [188 502]]\n",
            "  Noise Level: 25%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[589 211]\n",
            " [203 487]]\n",
            "  Noise Level: 30%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[560 240]\n",
            " [218 472]]\n",
            "  Noise Level: 35%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[527 273]\n",
            " [235 455]]\n",
            "  Noise Level: 40%\n",
            "  Confusion Matrix (sum over runs):\n",
            " [[489 311]\n",
            " [271 419]]\n",
            "  -> Completed label noise evaluations for Random Forest\n",
            "\n",
            "All models evaluated under different noise levels.\n"
          ]
        }
      ]
    }
  ]
}
